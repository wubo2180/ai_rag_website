from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from rest_framework.permissions import IsAuthenticated
from django.http import StreamingHttpResponse
from django.conf import settings
import json
import requests
import re
import time
from .models import ChatSession, ChatMessage
from .serializers import ChatMessageCreateSerializer


class StreamChatAPIView(APIView):
    """æµå¼èŠå¤©API - æ•´åˆAI_UI_928_2çš„æµå¼å“åº”åŠŸèƒ½"""
    permission_classes = []  # å…è®¸åŒ¿åè®¿é—®

    def post(self, request):
        """å¤„ç†æµå¼èŠå¤©è¯·æ±‚"""
        serializer = ChatMessageCreateSerializer(data=request.data)
        if not serializer.is_valid():
            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

        validated_data = serializer.validated_data
        message = validated_data['message']
        session_id = validated_data.get('session_id')
        model = validated_data.get('model', 'deepseek')
        deep_thinking = request.data.get('deep_thinking', False)

        # è·å–æˆ–åˆ›å»ºä¼šè¯
        session = None
        if session_id and request.user.is_authenticated:
            try:
                session = ChatSession.objects.get(id=session_id, user=request.user)
            except ChatSession.DoesNotExist:
                pass
        
        if not session and request.user.is_authenticated:
            # åˆ›å»ºæ–°ä¼šè¯
            session_title = message[:50] + '...' if len(message) > 50 else message
            session = ChatSession.objects.create(
                user=request.user,
                title=session_title
            )

        # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
        if session:
            ChatMessage.objects.create(
                session=session,
                content=message,
                is_user=True
            )

        # è¿”å›æµå¼å“åº”
        response = StreamingHttpResponse(
            self.generate_stream_response(message, model, deep_thinking, session, request),
            content_type='text/plain'
        )
        response['Cache-Control'] = 'no-cache'
        response['Connection'] = 'keep-alive'
        response['Access-Control-Allow-Origin'] = '*'
        return response

    def generate_stream_response(self, message, model, deep_thinking, session=None, request=None):
        """ç”Ÿæˆæµå¼å“åº”"""
        try:
            # APIé…ç½® - ä»AI_UI_928_2æ•´åˆ
            api_url = getattr(settings, 'DIFY_API_URL', 'http://744149f.r31.cpolar.top/v1/chat-messages')
            api_key = getattr(settings, 'DIFY_API_KEY', 'app-K9fjgkD8JbNrNfTH2ECIv4jw')
            
            # æ¨¡å‹æ˜ å°„ - ä¿®å¤ï¼šä½¿ç”¨ç»è¿‡éªŒè¯çš„æ¨¡å‹å
            model_mapping = {
                'deepseek': 'é€šä¹‰åƒé—®',  # ä¿®æ”¹ï¼šé»˜è®¤ä½¿ç”¨é€šä¹‰åƒé—®
                'doubao': 'è±†åŒ…',
                'gpt5': 'GPT-5', 
                'é€šä¹‰åƒé—®': 'é€šä¹‰åƒé—®',
                'claude4': 'Claude4'
            }

            # é€‰æ‹©æ¨¡å‹ - ä¿®å¤ï¼šåªæœ‰ç‰¹å®šç»„åˆæ”¯æŒæ·±åº¦æ€è€ƒ
            if model == 'deepseek' and deep_thinking:
                large_model = 'deepseekæ·±åº¦æ€è€ƒ'  # ä¿ç•™æ·±åº¦æ€è€ƒæ¨¡å¼
            else:
                large_model = model_mapping.get(model, 'é€šä¹‰åƒé—®')  # é»˜è®¤é€šä¹‰åƒé—®

            # æ„å»ºè¯·æ±‚ä½“ - ä½¿ç”¨ç»è¿‡éªŒè¯çš„æ ¼å¼
            request_body = {
                "inputs": {
                    "largeModel": large_model
                },
                "query": message,
                "user": f"user_{request.user.id if request and hasattr(request, 'user') and request.user.is_authenticated else 'anonymous'}",
                "response_mode": "streaming"
            }
            
            # åªåœ¨æœ‰ä¼šè¯IDæ—¶æ‰æ·»åŠ conversation_id
            if session and session.id:
                request_body["conversation_id"] = str(session.id)

            headers = {
                'Authorization': f'Bearer {api_key}',
                'Content-Type': 'application/json'
            }

            # åŠ¨æ€è¶…æ—¶é…ç½® - æ ¹æ®æ¨¡å‹è°ƒæ•´è¶…æ—¶æ—¶é—´
            model_timeouts = getattr(settings, 'AI_MODEL_TIMEOUTS', {})
            timeout_duration = model_timeouts.get(large_model, model_timeouts.get('default', 90))
            
            print(f"ğŸ• ä½¿ç”¨æ¨¡å‹ {large_model}ï¼Œè¶…æ—¶æ—¶é—´: {timeout_duration}ç§’")
            
            # è°ƒç”¨å¤–éƒ¨API
            response = requests.post(
                api_url,
                headers=headers,
                json=request_body,
                timeout=timeout_duration,  # ä½¿ç”¨åŠ¨æ€è¶…æ—¶
                stream=True
            )

            ai_content = ""
            thinking_content = ""

            if response.status_code == 200:
                # å¤„ç†æµå¼å“åº”
                for line in response.iter_lines():
                    if line:
                        line_str = line.decode('utf-8')
                        if line_str.startswith('data: '):
                            data_str = line_str[6:]
                            if data_str.strip() == '[DONE]':
                                break
                            try:
                                data = json.loads(data_str)
                                if 'answer' in data:
                                    content = data['answer']
                                    ai_content += content
                                    yield f"data: {json.dumps({'content': content})}\n\n"
                                
                                # å¦‚æœæœ‰æ·±åº¦æ€è€ƒå†…å®¹
                                if deep_thinking and 'thinking' in data:
                                    thinking = data['thinking']
                                    thinking_content += thinking
                                    yield f"data: {json.dumps({'thinking': thinking})}\n\n"
                                    
                            except json.JSONDecodeError:
                                continue

                # ä¿å­˜AIå“åº”
                if session and ai_content:
                    ai_message = ChatMessage.objects.create(
                        session=session,
                        content=ai_content,
                        is_user=False
                    )
                    # å¦‚æœæœ‰æ·±åº¦æ€è€ƒå†…å®¹ï¼Œä¹Ÿä¿å­˜
                    if thinking_content:
                        ai_message.metadata = {'thinking': thinking_content}
                        ai_message.save()

                yield "data: [DONE]\n\n"
            
            else:
                # è¯¦ç»†é”™è¯¯å¤„ç† - æ·»åŠ æ›´å¤šè°ƒè¯•ä¿¡æ¯
                try:
                    error_response = response.text
                    print(f"Dify API é”™è¯¯å“åº”: {response.status_code} - {error_response}")
                    
                    # å°è¯•è§£æé”™è¯¯JSON
                    try:
                        error_json = response.json()
                        if 'message' in error_json:
                            error_detail = error_json['message']
                        else:
                            error_detail = str(error_json)
                    except:
                        error_detail = error_response
                        
                    error_msg = f"Dify API é”™è¯¯ ({response.status_code}): {error_detail}"
                    
                except Exception as parse_error:
                    print(f"è§£æé”™è¯¯å“åº”å¤±è´¥: {parse_error}")
                    error_msg = f"AIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼ˆé”™è¯¯ä»£ç : {response.status_code}ï¼‰"
                
                yield f"data: {json.dumps({'content': error_msg})}\n\n"
                yield "data: [DONE]\n\n"

        except requests.exceptions.Timeout:
            yield f"data: {json.dumps({'content': 'è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•ã€‚'})}\n\n"
            yield "data: [DONE]\n\n"
        except Exception as e:
            print(f"æµå¼å“åº”ç”Ÿæˆé”™è¯¯: {e}")
            yield f"data: {json.dumps({'content': 'æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚'})}\n\n"
            yield "data: [DONE]\n\n"


class RelatedQuestionsAPIView(APIView):
    """ç›¸å…³é—®é¢˜æ¨èAPI - ä»AI_UI_928_2æ•´åˆ"""
    permission_classes = []  # å…è®¸åŒ¿åè®¿é—®

    def post(self, request):
        """è·å–ç›¸å…³é—®é¢˜æ¨è"""
        query = request.data.get('query', '').strip()
        
        if not query:
            return Response({
                'success': False,
                'suggestions': [],
                'error': 'æŸ¥è¯¢å†…å®¹ä¸èƒ½ä¸ºç©º'
            }, status=status.HTTP_400_BAD_REQUEST)

        suggestions = self.get_related_questions(query)
        
        return Response({
            'success': True,
            'suggestions': suggestions
        })

    def get_related_questions(self, query):
        """é€šè¿‡ç™¾åº¦APIè·å–ç›¸å…³é—®é¢˜æ¨è"""
        if not query:
            return []
        
        try:
            url = f"https://suggestion.baidu.com/su?wd={query}&p=3&cb=window.bdsug.sug"
            response = requests.get(url, timeout=5)
            response.raise_for_status()
            
            # è§£æç™¾åº¦å»ºè®®APIè¿”å›çš„JSONPæ ¼å¼
            match = re.search(r's:(\[.*?\])', response.text)
            if match:
                suggestions = json.loads(match.group(1))
                # è¿‡æ»¤æ‰ä¸åŸæŸ¥è¯¢ç›¸åŒçš„å»ºè®®
                filtered = [s for s in suggestions if s and s.lower().strip() != query.lower().strip()]
                return filtered[:5]  # è¿”å›å‰5ä¸ªå»ºè®®
                
        except Exception as e:
            print(f"è·å–ç›¸å…³é—®é¢˜æ—¶å‡ºé”™: {e}")
        
        # è¿”å›é»˜è®¤å»ºè®®
        return [
            f"å…³äº{query}çš„æ›´å¤šä¿¡æ¯",
            f"{query}çš„åº”ç”¨åœºæ™¯",
            f"{query}çš„ä¼˜ç¼ºç‚¹",
            f"å¦‚ä½•å­¦ä¹ {query}",
            f"{query}çš„å‘å±•è¶‹åŠ¿"
        ]


class EnhancedModelsAPIView(APIView):
    """å¢å¼ºç‰ˆå¯ç”¨æ¨¡å‹API - æ•´åˆæ›´å¤šAIæ¨¡å‹"""
    permission_classes = []

    def get(self, request):
        """è·å–å¯ç”¨çš„AIæ¨¡å‹åˆ—è¡¨"""
        models = [
            {
                'value': 'deepseek',
                'label': 'DeepSeekæ·±åº¦æ€è€ƒ',
                'description': 'æ”¯æŒæ·±åº¦æ€è€ƒæ¨¡å¼çš„AIæ¨¡å‹',
                'supports_thinking': True
            },
            {
                'value': 'doubao',
                'label': 'è±†åŒ…',
                'description': 'å­—èŠ‚è·³åŠ¨çš„å¤§è¯­è¨€æ¨¡å‹',
                'supports_thinking': False
            },
            {
                'value': 'gpt5',
                'label': 'GPT-5',
                'description': 'OpenAIæœ€æ–°å¤§è¯­è¨€æ¨¡å‹',
                'supports_thinking': False
            },
            {
                'value': 'é€šä¹‰åƒé—®',
                'label': 'é€šä¹‰åƒé—®',
                'description': 'é˜¿é‡Œäº‘çš„ä¸­æ–‡ä¼˜åŒ–å¤§æ¨¡å‹',
                'supports_thinking': False
            },
            {
                'value': 'claude4',
                'label': 'Claude 4',
                'description': 'Anthropicçš„å®‰å…¨AIæ¨¡å‹',
                'supports_thinking': False
            }
        ]
        
        return Response({
            'success': True,
            'models': models,
            'default_model': 'deepseek'
        })


class ChatModelSwitchAPIView(APIView):
    """èŠå¤©æ¨¡å‹åˆ‡æ¢API"""
    permission_classes = [IsAuthenticated]

    def post(self, request):
        """åˆ‡æ¢ç”¨æˆ·åå¥½çš„é»˜è®¤æ¨¡å‹"""
        model = request.data.get('model')
        deep_thinking = request.data.get('deep_thinking', False)
        
        # ä¿å­˜ç”¨æˆ·åå¥½åˆ°ç”¨æˆ·èµ„æ–™
        if hasattr(request.user, 'profile'):
            profile = request.user.profile
            profile.preferred_ai_model = model
            profile.enable_deep_thinking = deep_thinking
            profile.save()
        
        return Response({
            'success': True,
            'message': 'æ¨¡å‹è®¾ç½®å·²ä¿å­˜',
            'model': model,
            'deep_thinking': deep_thinking
        })

    def get(self, request):
        """è·å–ç”¨æˆ·çš„æ¨¡å‹åå¥½"""
        default_model = 'deepseek'
        default_deep_thinking = True
        
        if hasattr(request.user, 'profile'):
            profile = request.user.profile
            default_model = getattr(profile, 'preferred_ai_model', default_model)
            default_deep_thinking = getattr(profile, 'enable_deep_thinking', default_deep_thinking)
        
        return Response({
            'success': True,
            'model': default_model,
            'deep_thinking': default_deep_thinking
        })